{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Автокорректор ошибок на Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе блокнота Питера Норвига, Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим \"модель\" грамматически правильного текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6488666"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = requests.get('http://norvig.com/big.txt').text\n",
    "len(TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно разбить текст на слова (aka токены). Сосредоточимся только на словах, состоящих из букв. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens(text):\n",
    "    \"\"\"Возвращает список токенов (подряд идущих буквенных последовательностей) в тексте.\n",
    "    Также приводим текст к нижнему регистру\"\"\"\n",
    "    return re.findall(r'[a-z]+', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'test', 'this', 'is']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens('This is: A test, 1 , 2, 3. this is.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105285"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS = tokens(TEXT)\n",
    "len(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'adventures', 'of', 'sherlock', 'holmes']\n"
     ]
    }
   ],
   "source": [
    "print(WORDS[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас слова появляются в списке в том порядке, как они располагались в тексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем использовать _TEXT_ (список) в качестве *порождающей модели* (generative model) текста. Мы создаём всё же упрощённую модель языка, которая ухватывает часть её сложной структуры. В модели Bag if Words игнорируется порядок слов, но соблюдается частота (представить мешок из игры Лото). Почти наверное полученное предложение из мешка будет грамматически некорректным, но слова в этом предложении будут в +- правильной пропорции (более частные будут встречаться чаще, более редкие - реже). \n",
    "Напишем функцию, которая сэмплирует предложение из n слов с помощью данной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(bag, n=10):\n",
    "    \"\"\"Сэмплируем случайную последовательность из n слов из модели, описанной нашим мешком слов.\"\"\"\n",
    "    return ' '.join(random.choice(bag) for _ in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smiled hour and so at voice of and to associated'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другое представление мешка слов - Counter. Он содержит в себе ка качестве value кол-во вхождений слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'is': 2, 'this': 1, 'a': 2, 'test': 2, 'it': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(tokens('Is this a test? It is a test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 80030), ('of', 40025), ('and', 38313), ('to', 28766), ('in', 22050), ('a', 21155), ('that', 12512), ('he', 12401), ('was', 11410), ('it', 10681)]\n"
     ]
    }
   ],
   "source": [
    "COUNTS = Counter(WORDS)\n",
    "print(COUNTS.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80030 the\n",
      "83 rare\n",
      "38313 and\n",
      "0 neverbeforeseen\n",
      "460 words\n"
     ]
    }
   ],
   "source": [
    "for w in tokens('the rare and neverbeforeseen words'):\n",
    "    print(COUNTS[w], w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 1935 году лингвист Джордж Ципф отметил, что в любом большом тексте n-ое наиболее часто встречающееся слово появляется с частотой - 1/n от частоты наиболее часто встречающегося слова. Это наблюдение получило название _Закона Ципфа_, несмотря на то, что Феликс Ауэрбах заметил это ещё в 1913 году. Если нарисовать частоты слов, начиная от самого часто встречающегося, на log-log-графике, они должны приблизительно следовать прямой линии, если закон Ципфа верен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29157"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(COUNTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15081908>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "M = COUNTS['the']\n",
    "yscale('log')\n",
    "xscale('log')\n",
    "title('Частота n-того наиболее часто встречающегося слова и линия 1/n')\n",
    "plot([c for (w, c) in COUNTS.most_common()])\n",
    "plot([M / i for i in range(1, len(COUNTS))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка правописания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подход**: найти все кандидаты _c = correct(w)_, достаточно близкие к *w*. Выбрать наиболее вероятный из них.\n",
    "\n",
    "Применим наивный подход: всегда будем брать более близкое слово, если проверки на близость недостаточно, берём слово с максимальной частотой из WORDS. Сейчас измерим близость с помощью расстояния Леверштейна: минимального необходимого количества удалений, перестановок, вставок и замен символов, необходимых, чтобы одно слово превратилось в другое. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    \"\"\"Поиск лучшего исправления ошибки для слова\"\"\"\n",
    "    candidates = (known(edits0(word)) or\n",
    "                 known(edits1(word)) or\n",
    "                 known(edits2(word)) or\n",
    "                 [word])\n",
    "    return max(candidates, key=COUNTS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    \"\"\"Вернуть множество слов, которые есть в нашем словаре\"\"\"\n",
    "    return {w for w in words if w in COUNTS}\n",
    "\n",
    "def edits0(word):\n",
    "    \"\"\"Вернуть все строки, которые находятся на edit_distance == 0 от word\"\"\"\n",
    "    return {word}\n",
    "\n",
    "def edits2(word):\n",
    "    \"\"\"Вернуть все строки, которые находятся на edit_distance == 1 от word\"\"\"\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_lowercase as alphabet\n",
    "\n",
    "def edits1(word):\n",
    "    \"\"\"Возвращает список всех строк на расстоянии edit_distance == 1 от word\"\"\"\n",
    "    pairs = splits(word)\n",
    "    deletes = [a + b[1:]                     for (a, b) in pairs if b]\n",
    "    transposes = [a + b[1:] + b[0] + b[2:]   for (a, b) in pairs if len(b) > 1]\n",
    "    replaces = [a + c + b[1:]                for (a, b) in pairs \n",
    "                                                 for c in alphabet if b]\n",
    "    inserts = [a + c + b                     for (a, b) in pairs \n",
    "                                                 for c in alphabet]\n",
    "    \n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "    \n",
    "def splits(word):\n",
    "    \"\"\"Возвращает список всех возможных разбиений слова на пару (a, b)\"\"\"\n",
    "    return [(word[:i], word[i:]) for i in range(len(word) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'wirds'),\n",
       " ('w', 'irds'),\n",
       " ('wi', 'rds'),\n",
       " ('wir', 'ds'),\n",
       " ('wird', 's'),\n",
       " ('wirds', '')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits('wirds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wird'}\n"
     ]
    }
   ],
   "source": [
    "print(edits0('wird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wrd', 'wirh', 'wmird', 'wierd', 'wixrd', 'iwird', 'wiid', 'wirv', 'hird', 'wiqd', 'wircd', 'wira', 'kird', 'wirzd', 'yird', 'wlird', 'wirdl', 'wirq', 'wirdw', 'wirs', 'wipd', 'wfird', 'rird', 'twird', 'wibd', 'qwird', 'dwird', 'wrird', 'wirud', 'wied', 'pwird', 'wkird', 'wirqd', 'wirdb', 'wirx', 'wkrd', 'nird', 'wiod', 'iird', 'wirwd', 'mird', 'dird', 'wimrd', 'whird', 'wirdd', 'wired', 'wxird', 'wiwrd', 'wicd', 'wwird', 'wiird', 'wirdz', 'wire', 'sird', 'wirb', 'wcird', 'wiyd', 'witrd', 'wirde', 'wilrd', 'wirfd', 'wirr', 'mwird', 'wyird', 'wgrd', 'wirdr', 'wnird', 'widr', 'zird', 'wiad', 'wiry', 'aird', 'wdrd', 'wirc', 'awird', 'werd', 'wind', 'wirl', 'hwird', 'cird', 'wbird', 'wirtd', 'wirdh', 'wirjd', 'wirdx', 'wirdf', 'wprd', 'wsird', 'wsrd', 'wirad', 'bird', 'wirdn', 'wirdp', 'witd', 'lird', 'wikd', 'wisrd', 'wlrd', 'wiro', 'jwird', 'wrdid', 'gwird', 'vwird', 'wirdi', 'wirpd', 'wtird', 'wirld', 'wqrd', 'ward', 'wiud', 'wijrd', 'lwird', 'wirdj', 'waird', 'wimd', 'wirf', 'wiri', 'wirm', 'wiprd', 'wirbd', 'fwird', 'ewird', 'winrd', 'owird', 'wiwd', 'woird', 'wirdv', 'wtrd', 'pird', 'wird', 'wjird', 'wirk', 'wgird', 'ywird', 'wizd', 'wiord', 'wirdo', 'vird', 'wirdt', 'wuird', 'wihrd', 'wiqrd', 'xwird', 'wirvd', 'nwird', 'jird', 'wihd', 'wid', 'wirdm', 'wfrd', 'wwrd', 'word', 'wisd', 'wirg', 'wqird', 'wmrd', 'wirda', 'wirdy', 'weird', 'zwird', 'wxrd', 'wirz', 'wzird', 'wirt', 'wbrd', 'wrrd', 'widrd', 'wirw', 'oird', 'wirod', 'wijd', 'wifd', 'wiryd', 'wigrd', 'widd', 'wurd', 'wigd', 'wifrd', 'cwird', 'wibrd', 'gird', 'wirkd', 'wirdk', 'wirp', 'wirid', 'wpird', 'fird', 'wirdg', 'whrd', 'wir', 'wirj', 'wirrd', 'qird', 'uwird', 'eird', 'wikrd', 'kwird', 'tird', 'wdird', 'wirhd', 'wirdu', 'swird', 'wivd', 'irdwrd', 'wivrd', 'wirsd', 'wirdc', 'wiyrd', 'wirds', 'bwird', 'wicrd', 'wzrd', 'wirdq', 'wyrd', 'wvrd', 'wirgd', 'wnrd', 'wild', 'wiru', 'wjrd', 'wixd', 'xird', 'wiard', 'wcrd', 'wirmd', 'wizrd', 'ird', 'uird', 'wirn', 'wiurd', 'wirnd', 'rwird', 'wvird', 'wirxd'}\n"
     ]
    }
   ],
   "source": [
    "print(edits1('wird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24953\n"
     ]
    }
   ],
   "source": [
    "print(len(edits2('wird')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['speling',\n",
       " 'errurs',\n",
       " 'in',\n",
       " 'somethink',\n",
       " 'whutever',\n",
       " 'unusuel',\n",
       " 'misteakes',\n",
       " 'everyware']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens('Speling errurs in somethink. Whutever; unusuel misteakes everyware?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spelling',\n",
       " 'errors',\n",
       " 'in',\n",
       " 'something',\n",
       " 'whatever',\n",
       " 'unusual',\n",
       " 'mistakes',\n",
       " 'everywhere']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(correct, tokens('Speling errurs in somethink. Whutever; unusuel misteakes everyware?')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем выходные данные более приятными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text(text):\n",
    "    return re.sub('[a-zA-Z]+', correct_match, text)\n",
    "\n",
    "def correct_match(match):\n",
    "    word = match.group()\n",
    "    return case_of(word)(correct(word.lower()))\n",
    "\n",
    "def case_of(text):\n",
    "    return (str.upper if text.isupper() else\n",
    "           str.lower if text.islower() else\n",
    "           str.title if text.istitle() else\n",
    "           str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<method 'upper' of 'str' objects>,\n",
       " <method 'lower' of 'str' objects>,\n",
       " <method 'title' of 'str' objects>,\n",
       " str]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(case_of, ['UPPER', 'lower', 'Title', 'CamelCase']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spelling errors IN something. Whatever; unusual mistakes everywhere?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text('Speling errurs IN somethink. Whutever; unusuel misteakes everyware?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория: от счётчика слов к вероятностям последовательностей слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужно научиться подсчитывать вероятности слов, _P(w)_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdist(counter):\n",
    "    \"\"\"Превращает частоты из Counter в вероятностное распределение\"\"\"\n",
    "    N = sum(list(counter.values()))\n",
    "    return lambda x: counter[x] / N\n",
    "\n",
    "P = pdist(COUNTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07240666434449033 the\n",
      "0.008842968103249388 is\n",
      "0.07240666434449033 the\n",
      "0.0008215075749693518 most\n",
      "0.0002596615352601365 common\n",
      "0.0002696137195383996 word\n",
      "0.019949605757790978 in\n",
      "0.00019090098933759167 english\n"
     ]
    }
   ],
   "source": [
    "for w in tokens('\"The\" is the most common word in English'):\n",
    "    print(P(w), w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pwords(words):\n",
    "    \"\"\"Вероятности слов, при условии, что они независимы\"\"\"\n",
    "    return product(P(w) for w in words)\n",
    "\n",
    "def product(nums):\n",
    "    \"\"\"Перемножим числа\"\"\"\n",
    "    result = 1\n",
    "    for x in nums:\n",
    "        result *= x\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.983396332800731e-11 this is a test\n",
      "1.3975923769696695e-16 this is an unusual test\n",
      "0.0 this is neverbeforeseen test\n"
     ]
    }
   ],
   "source": [
    "tests = ['this is a test',\n",
    "        'this is an unusual test',\n",
    "        'this is neverbeforeseen test']\n",
    "\n",
    "for test in tests:\n",
    "    print(Pwords(tokens(test)), test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВОУ - присвоить последнюю вероятность 0 - неправильно. Она просто должна стремиться к ней. Этот момент рассмотрим позже. Другие вероятности +- адекватные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение слов на сегменты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# декоратор\n",
    "def memo(f):\n",
    "    \"\"\"Запомнить результаты исполнения фуункции f, чьи аргументы args должны быть хешируемыми\"\"\"\n",
    "    cache = {}\n",
    "    def fmemo(*args):\n",
    "        if args not in cache:\n",
    "            cache[args] = f(*args)\n",
    "        return cache[args]\n",
    "    fmemo.cache = cache\n",
    "    return fmemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переиспользование предыдущих результатов - очень инстересная штука."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in COUNTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits(text, start=0, L=20):\n",
    "    \"\"\"Вернуть список всех пар (a, b); start <= len(a) <= L\"\"\"\n",
    "    return [(text[:i], text[i:])\n",
    "           for i in range(start, min(len(text), L) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 'word'), ('w', 'ord'), ('wo', 'rd'), ('wor', 'd'), ('word', '')]\n",
      "[('r', 'eallylongtext'), ('re', 'allylongtext'), ('rea', 'llylongtext'), ('real', 'lylongtext')]\n"
     ]
    }
   ],
   "source": [
    "print(splits('word'))\n",
    "print(splits('reallylongtext', 1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memo\n",
    "def segment(text):\n",
    "    \"\"\"Вернуть список слов, который является наиболее вероятной сегментацией нашего текста\"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    else:\n",
    "        candidates = ([first] + segment(rest)\n",
    "                     for (first, rest) in splits(text, 1))\n",
    "        return max(candidates, key=Pwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib(40) = 102334155\n",
      "0.002422002999992401\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "@memo\n",
    "def fib(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fib(n-2) + fib(n-1)\n",
    "\n",
    "x = 40\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "print(f'fib({x}) =', fib(x))\n",
    "print(time.perf_counter() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s', 'pe', 'et', 'of', 'art']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment('speetofart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pwords(segment('speedof art'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Присутствует проблема переполнения разрядности числа.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['small', 'and', 'insignificant']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment('smallandinsignificant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['large', 'and', 'insignificant']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment('largeandinsignificant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.111418791681202e-10\n",
      "1.0662753919897733e-11\n"
     ]
    }
   ],
   "source": [
    "print(Pwords(['large', 'and', 'insignificant']))\n",
    "print(Pwords(['large', 'and', 'in', 'significant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого:\n",
    "- Предположение о мешке слов имеет ряд ограничений;\n",
    "- Пересчёт pwods на каждом вызове выглядит неэффективным;\n",
    "- Переполнение чисел возникает для текстов длиннее +- 100 слов, придётся использовать логарифмы или ещё какие-то хитрости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные: Mo'Data, Mo'Better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам мало миллионов слов в \"обучающей выборке\" давайте перейдем к МИЛЛИАРДАМ слов. Получив такой огромный объем информации, можно перейти к анализу пар последоваительных слов, не ожидая, что вероятности слишком часто будут обнуляться (представьте себе, сколько в языке может быть грамматически корректных сочетаний из двух слов). Мы вновь позаимствуем уже собранные данные у мистера Норвига. Лежат они на его сайте в формате \"word \\t count\" для отдельных слов и в формате \"word1 word2 \\t count\" для биграмм. Считаем их и упакуем в наши словари с вероятностями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_counts(text, sep='\\t'):\n",
    "    \"\"\"Возвращает Counter, полученный из пар ключ-значение,в каждой строке файла.\"\"\"\n",
    "    C = Counter()\n",
    "    for i in [l.split('\\t') for l in text.split('\\n')][:-1]:\n",
    "        key, count = i\n",
    "        C[key] = int(count)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTS1 = load_counts(requests.get('https://www.norvig.com/ngrams/count_1w.txt').text)\n",
    "COUNTS2 = load_counts(requests.get('https://www.norvig.com/ngrams/count_2w.txt').text)\n",
    "\n",
    "P1w = pdist(COUNTS1)\n",
    "P2w = pdist(COUNTS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333333 588.124220187\n",
      "286358 225.955251755\n"
     ]
    }
   ],
   "source": [
    "print(len(COUNTS1), sum(list(COUNTS1.values()))/1e9)\n",
    "print(len(COUNTS2), sum(list(COUNTS2.values()))/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of the', 2766332391),\n",
       " ('in the', 1628795324),\n",
       " ('to the', 1139248999),\n",
       " ('on the', 800328815),\n",
       " ('for the', 692874802),\n",
       " ('and the', 629726893),\n",
       " ('to be', 505148997),\n",
       " ('is a', 476718990),\n",
       " ('with the', 461331348),\n",
       " ('from the', 428303219),\n",
       " ('by the', 417106045),\n",
       " ('at the', 416201497),\n",
       " ('of a', 387060526),\n",
       " ('in a', 364730082),\n",
       " ('will be', 356175009),\n",
       " ('that the', 333393891),\n",
       " ('do not', 326267941),\n",
       " ('is the', 306482559),\n",
       " ('to a', 279146624),\n",
       " ('is not', 276753375),\n",
       " ('for a', 274112498),\n",
       " ('with a', 271525283),\n",
       " ('as a', 270401798),\n",
       " ('<S> and', 261891475),\n",
       " ('of this', 258707741),\n",
       " ('<S> the', 258483382),\n",
       " ('it is', 245002494),\n",
       " ('can be', 230215143),\n",
       " ('If you', 210252670),\n",
       " ('has been', 196769958)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COUNTS2.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория и Практика: Сегментация с помощью биграмм\n",
    "Чуть менее неправильная аппроксимация:\n",
    "\n",
    "$P(w_1 \\ldots w_n) = P(w_1) \\times P(w_2 \\mid w_1) \\times P(w_3 \\mid w_2) \\ldots  \\times \\ldots P(w_n \\mid w_{n-1})$\n",
    "\n",
    "Эта штука называется биграммной моделью. Представьте, что вы взяли текст, достали из него все возможные пары подряд идущих слов и положили каждую пару в мешок, промаркированный ПЕРВЫМ словом из пары. После этого, чтобы сгенерировать кусок текста, мы берем первое слово из исходного мешка слов , а каждое следующее слово вынимаем из соответствующего мешка биграмм.\n",
    "\n",
    "Начнем с определения вероятности текущего слова при условии данного предыдущего слова из Counter:\n",
    "\n",
    "Отмечу, что для английского языка биграммная модель будет выглядеть так:\n",
    "\n",
    "$P(w_1 \\ldots w_n) = P(w_1) \\times P(w_2 \\mid w_1) \\times P(w_3 \\mid w_2) \\ldots  \\times \\ldots P(w_n \\mid w_{n-1})$\n",
    "\n",
    "условная вероятность слова при условии предыдущего слова определяется так:\n",
    "\n",
    "$P(w_n \\mid w_{n-1}) = P(w_{n-1}w_n) / P(w_{n-1}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pwords2(words, prev='<S>'):\n",
    "    \"Вероятность последовательности слов с помощью биграммной модели(при условии предыдущего слова).\"\n",
    "    return product(cPword(w, (prev if (i == 0) else words[i-1]) )\n",
    "                   for (i, w) in enumerate(words))\n",
    "\n",
    "# Перепишем Pwords на большой словарь P1w вместо Pword\n",
    "def Pwords(words):\n",
    "    \"Вероятности слов при условии их независимости.\"\n",
    "    return product(P1w(w) for w in words)\n",
    "\n",
    "def cPword(word, prev):\n",
    "    \"Условная вероятность слова при условии предыдущего.\"\n",
    "    bigram = prev + ' ' + word\n",
    "    if P2w(bigram) > 0 and P1w(prev) > 0:\n",
    "        return P2w(bigram) / P1w(prev)\n",
    "    else: # если что-то не встретилось, поставим среднее между P1w и 0\n",
    "        return P1w(word) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7873982000630825e-10\n",
      "6.413676294377262e-08\n",
      "1.1802860036709024e-11\n"
     ]
    }
   ],
   "source": [
    "print(Pwords(tokens('this is a test')))\n",
    "print(Pwords2(tokens('this is a test')))\n",
    "print(Pwords2(tokens('is test a this')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сделать segment2, скопируем segment, добавим в аргументы предыдущий токен, а вероятности будем считать с помощью Pwords2 вместо Pwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memo \n",
    "def segment2(text, prev='<S>'): \n",
    "    \"Возвращает наилучшее разбиение текста, используя статистику биграмм.\" \n",
    "    if not text: \n",
    "        return []\n",
    "    else:\n",
    "        candidates = ([first] + segment2(rest, first) \n",
    "                      for (first, rest) in splits(text, 1))\n",
    "        return max(candidates, key=lambda words: Pwords2(words, prev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['choose', 'spain']\n",
      "['speed', 'of', 'art']\n",
      "['small', 'and', 'in', 'significant']\n",
      "['large', 'and', 'in', 'significant']\n"
     ]
    }
   ],
   "source": [
    "print(segment2('choosespain'))\n",
    "print(segment2('speedofart'))\n",
    "print(segment2('smallandinsignificant'))\n",
    "print(segment2('largeandinsignificant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['far', 'out', 'in', 'the', 'uncharted', 'backwaters', 'of', 'the', 'unfashionable', 'end', 'of', 'the', 'western', 'spiral', 'arm', 'of', 'the', 'galaxy', 'lies', 'a', 'small', 'un', 'regarded', 'yellow', 'sun']\n",
      "['far', 'out', 'in', 'the', 'uncharted', 'backwaters', 'of', 'the', 'unfashionable', 'end', 'of', 'the', 'western', 'spiral', 'arm', 'of', 'the', 'galaxy', 'lies', 'a', 'small', 'un', 'regarded', 'yellow', 'sun']\n"
     ]
    }
   ],
   "source": [
    "adams = ('faroutintheunchartedbackwatersoftheunfashionableendofthewesternspiral' +\n",
    "         'armofthegalaxyliesasmallunregardedyellowsun')\n",
    "print(segment(adams))\n",
    "print(segment2(adams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1w('unregarded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'herecomeoldflattophecomegroovingupslowlyhegotjoojooeyeballheoneholyrollerhegothairdowntohiskneegottobeajokerhejustdowhatheplease'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles = \"\"\"Here come old flattop he come grooving up slowly \n",
    "          He got joo-joo eyeball he one holy roller \n",
    "          He got hair down to his knee \n",
    "          Got to be a joker he just do what he please\"\"\"\n",
    "beatles = ''.join(re.findall(r'[a-z]',beatles.lower()))\n",
    "beatles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'dry', 'bare', 'sandy', 'hole', 'with', 'nothing', 'in', 'it', 'to', 'sitdown', 'on', 'or', 'to', 'eat']\n",
      "['a', 'dry', 'bare', 'sandy', 'hole', 'with', 'nothing', 'in', 'it', 'to', 'sit', 'down', 'on', 'or', 'to', 'eat']\n"
     ]
    }
   ],
   "source": [
    "tolkien = 'adrybaresandyholewithnothinginittositdownonortoeat'\n",
    "print(segment(tolkien))\n",
    "print(segment2(tolkien))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'come', 'old', 'flattop', 'he', 'come', 'grooving', 'up', 'slowly', 'he', 'got', 'joo', 'joo', 'eyeball', 'he', 'one', 'holy', 'roller', 'he', 'got', 'hair', 'down', 'to', 'his', 'knee', 'got', 'to', 'be', 'a', 'joker', 'he', 'just', 'do', 'what', 'he', 'please']\n",
      "['here', 'come', 'old', 'flattop', 'he', 'come', 'grooving', 'up', 'slowly', 'he', 'got', 'joo', 'joo', 'eyeball', 'he', 'one', 'holy', 'roller', 'he', 'got', 'hair', 'down', 'to', 'his', 'knee', 'got', 'to', 'be', 'a', 'joker', 'he', 'just', 'do', 'what', 'he', 'please']\n"
     ]
    }
   ],
   "source": [
    "print(segment(beatles))\n",
    "print(segment2(beatles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория: Валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До настоящего момента мы пытались интуитивно оценить результаты нашей работы. Тем не менее, никаких численных оценок качества мы пока не получили. Важно понимать, что без четких метрик слова \"плохо\"/\"хорошо\" не имеют никакого смысла. Более того - мы даже не можем четко ответить, было ли наше обновление модели в лучшую сторону или худшую. Обычно при построении неких прогностических моделей данные разбиваются на три части:\n",
    "\n",
    "1. Обучающая выборка: То, что мы использовали для создания модели исправления ошибок; У нас это был файл big.txt file.\n",
    "2. Тестовая выборка: Набор данных, который можно использовать для оценки качества вашей модели по ходу разработки.\n",
    "3. Валидационная выборка: Набор данных, который мы используем для оценки работы программы после того как программа готова. Тестовая выборка для этого быть использована не может—Стоит разработчику посмотреть на результаты на тестовой выборке, она уже \"испорчена\". В принципе, программист может изменить программу так, чтобы она \"подгонялась\" под тестовую выборку, а это будет \"переобучением\". Вот почему нам нужен отдельный набор тестов, который рассматривается только после завершения разработки..\n",
    "\n",
    "Для нашей программы обучающая выборка - словарь с частотами слов, а тестовая выборка - набор примеров типа \"choosespain\", на которых мы отлаживались. Остается сделать валидационную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_segmenter(segmenter, tests):\n",
    "    \"Оценка сегментатора на тестовых данных; вывести на печать ошибки; вернуть долю верно разбитого.\"\n",
    "    return sum([test_one_segment(segmenter, test) \n",
    "               for test in tests]), len(tests)\n",
    "\n",
    "def test_one_segment(segmenter, test):\n",
    "    words = tokens(test)\n",
    "    result = segmenter(''.join(words))\n",
    "    correct = (result == words)\n",
    "    if not correct:\n",
    "        print('expected', words)\n",
    "        print('got     ', result) \n",
    "    return correct\n",
    "\n",
    "proverbs = (\"\"\"A little knowledge is a dangerous thing\n",
    "  A man who is his own lawyer has a fool for his client\n",
    "  All work and no play makes Jack a dull boy\n",
    "  Better to remain silent and be thought a fool that to speak and remove all doubt;\n",
    "  Do unto others as you would have them do to you\n",
    "  Early to bed and early to rise, makes a man healthy, wealthy and wise\n",
    "  Fools rush in where angels fear to tread\n",
    "  Genius is one percent inspiration, ninety-nine percent perspiration\n",
    "  If you lie down with dogs, you will get up with fleas\n",
    "  Lightning never strikes twice in the same place\n",
    "  Power corrupts; absolute power corrupts absolutely\n",
    "  Here today, gone tomorrow\n",
    "  See no evil, hear no evil, speak no evil\n",
    "  Sticks and stones may break my bones, but words will never hurt me\n",
    "  Take care of the pence and the pounds will take care of themselves\n",
    "  Take care of the sense and the sounds will take care of themselves\n",
    "  The bigger they are, the harder they fall\n",
    "  The grass is always greener on the other side of the fence\n",
    "  The more things change, the more they stay the same\n",
    "  Those who do not learn from history are doomed to repeat it\"\"\".splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected ['sticks', 'and', 'stones', 'may', 'break', 'my', 'bones', 'but', 'words', 'will', 'never', 'hurt', 'me']\n",
      "got      ['stick', 'sandstones', 'may', 'break', 'my', 'bones', 'but', 'words', 'will', 'never', 'hurt', 'me']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19, 20)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_segmenter(segment, proverbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_segmenter(segment2, proverbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория и Практика: Сглаживание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7873982000630825e-10 this is a test\n",
      "3.7867542527781925e-15 this is a unusual test\n",
      "1.3117947423493677e-16 this is a nongovernmental test\n",
      "0.0 this is a neverbeforeseen test\n",
      "0.0 this is a zqbhjhsyefvvjqc test\n"
     ]
    }
   ],
   "source": [
    "tests = ['this is a test', \n",
    "         'this is a unusual test',\n",
    "         'this is a nongovernmental test',\n",
    "         'this is a neverbeforeseen test',\n",
    "         'this is a zqbhjhsyefvvjqc test']\n",
    "\n",
    "for test in tests:\n",
    "    print(Pwords(tokens(test)), test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема в том, что вероятность одного из слов - 0. Среди этих трех 15-букваенных слов, \"nongovernmental\" в нашем словаре есть, но если б его не было, вся вероятность бы обнулилась (мы же считаем произведение). Кажется, что это слишком строгое условие; Словарь не идеален и точно существуют реальные слова, которых мы не увидели. Давайте не будем все сразу обнулять. Например точно должна быть оценка вероятности того, что слово настоящее. Скажем, \"neverbeforeseen\" уж явно более английское чем \"zqbhjhsyefvvjqc\" и должно иметь бОльшую вероятность.\n",
    "\n",
    "Проблему можно побороть, присвоив таким \"не встретившимся\" словам ненулевую вероятность. Еще более важным этот пункт становится при переходе к токенам из нескольких слов (биграммам, например), потому что чем больше слов в токене, тем больше вероятность, что какой-то реальный токен в нашей обучающей выборке отсутствует.\n",
    "\n",
    "Нашу модель можно представить в виде забора вероятностей, где столбик равен вероятности слова/токена, которое/который в выборке было/был, и равен 0, если слова/токена в выборке не было; Мы хотим сгладить наше распределение вокруг этих пиков, чтобы модель давала какой-то ответ вне зависимости от наличия или отсутствия слова в корпусе. Этот процесс и называется сглаживанием."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однажды французского математика Лапласа спросили: \"Какова вероятность того, что Солнце завтра взойдет?\". Из данных, что оно из $n$ ближайших дней взошло $n$ раз следует оценка максимального правдоподобия $n/n$ = 1. Но Лапласу хотелось чуть сбалансировать оценку на шанс того, что завтра Солнце может и не взойти, поэтому он дал оценку $(n + 1) / (n + 2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdist_additive_smoothed(counter, c=1):\n",
    "    \"\"\"Вероятность слова, при условии данных из Counter'a.\n",
    "    добавляем c к частоте каждого слова + слово 'unknown'.\"\"\"\n",
    "    N = sum(list(counter.values()))          # суммарное кол-во слов\n",
    "    Nplus = N + c * (len(counter) + 1) # кол-во слов + сглаживание\n",
    "    return lambda word: (counter[word] + c) / Nplus \n",
    "\n",
    "P1w = pdist_additive_smoothed(COUNTS1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7003201005861308e-12"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1w('neverbeforeseen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь еще одна проблема ... у нас появились незнакомые слова с ненулевой вероятностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thisisatestofsegment', 'ationofalongsequence', 'of', 'words']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment('thisisatestofsegmentationofalongsequenceofwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас две проблемы:\n",
    "\n",
    "Во-первых, у нас нет четкой модели для неизвестных слов. Мы говорим \"неизвестное слово\", но не различаем более вероятные неизвестные слова и менее вероятные неизвестные слова. Ну, например, вероятнее ли 8-буквенное неизвестное слово чем 20-буквенное неизвестное слово?\n",
    "\n",
    "Во-вторых, мы не берем в расчет информацию из частей неизвестных слов. Например, \"unglobulate\" явно должно быть более вероятным чем \"zxfkogultae\".\n",
    "\n",
    "Для нашего следующего подхода мы используем идеи метода Гуда - Тьюринга. Он оценивает вероятности слов, не встретившихся в нашем Counter'е, на основании вероятностей слов, встретившихся единожды (Можно туда же подключить вероятности для встретившихся 2 раза и т.д.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 1357),\n",
       " (8, 1356),\n",
       " (9, 1175),\n",
       " (6, 1113),\n",
       " (10, 938),\n",
       " (5, 747),\n",
       " (11, 627),\n",
       " (12, 398),\n",
       " (4, 368),\n",
       " (13, 215),\n",
       " (3, 159),\n",
       " (14, 112),\n",
       " (2, 51),\n",
       " (15, 37),\n",
       " (16, 10),\n",
       " (17, 7)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singletons = (w for w in COUNTS if COUNTS[w] == 1)\n",
    "lengths = list(map(len, singletons))\n",
    "Counter(lengths).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1357 / sum(COUNTS.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(lengths, bins=len(set(lengths)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdist_good_turing_hack(counter, onecounter, base=1/26., prior=1e-8):\n",
    "    \"\"\"Вероятность слова при условии данных из счетчика.\n",
    "    Для неизвестных слов, смотрим на слова, встретившиеся единожды из onecounter, \n",
    "    вероятность выбираем, основываясь на длине.\n",
    "    Воспользуемся идеей метода Гуда-Тьюринга(полностью мы его здесь не реализуем).\n",
    "    prior -добавочный фактор, который сделает неизвестные слова менее вероятными.\n",
    "    base -то, насколько мы уменьшаем вероятность за длину слова больше максимального.\"\"\"\n",
    "    N = sum(list(counter.values()))\n",
    "    N2 = sum(list(onecounter.values()))\n",
    "    lengths = list(map(len, [w for w in onecounter if onecounter[w] == 1]))\n",
    "    ones = Counter(lengths)\n",
    "    longest = max(ones)\n",
    "    return (lambda word: \n",
    "            counter[word] / N if (word in counter) \n",
    "            else prior * (ones[len(word)] / N2 or \n",
    "                          ones[longest] / N2 * base ** (len(word)-longest)))\n",
    "#Переопределим P1w\n",
    "P1w = pdist_good_turing_hack(COUNTS1, COUNTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'test',\n",
       " 'of',\n",
       " 'segmentation',\n",
       " 'of',\n",
       " 'a',\n",
       " 'very',\n",
       " 'long',\n",
       " 'sequence',\n",
       " 'of',\n",
       " 'words']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment.cache.clear()\n",
    "segment('thisisatestofsegmentationofaverylongsequenceofwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача: Что если слово находится очень далеко по edit_distance, но звучит точно так же?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(11) Задача: Что если слово находится очень далеко по edit_distance, но звучит точно так же?\n",
    "Часто можно встретить ошибки в текстах, вызванные неграмотным написанием слов. Особенно часто это происходит в случае иностранных фамилий или транслитерированной терминологии. Обычно в таких случаях в пример приводят написание фамилии\n",
    "\n",
    "Schwartzenegger\n",
    "\n",
    "в виде:\n",
    "\n",
    "Shwarzenegger, Shwortsinneger, schwartzineger ... und so weiter\n",
    "\n",
    "Для такого случая можно использовать следующую методологию. Давайте привлечем лингвистов и составим правила, которые одинаково звучащим словам будут ставить в соответствие один и тот же код. Допустим, с помощью лингвистов мы такой алгоритм придумали. Тогда дальнейшие наши действия таковы:\n",
    "\n",
    "1) Сделать словарь с вероятностями слов (как мы делали из мешка слов)\n",
    "\n",
    "2) Сделать словарь соответствий код слова -> слово (с помощью того самого алгоритма от лингвистов). \n",
    "    Если есть в списке есть слова с одинаковым кодом, выбирать будем наиболее частое слово.\n",
    "\n",
    "3) Сделаем аналогичный edit_distance алгоритм на множестве кодов слов\n",
    "\n",
    "4) Найдя соответствующую замену для слова в виде его кода, восстановим слово с помощью словаря из пункта 2\n",
    "\n",
    "Алгоритм, про который мы поговорим, называется Double Metaphone. Примеры есть тут. Перейдем к делу, посмотрим, как это работает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'metaphone'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-d9455769ae76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmetaphone\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdoublemetaphone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'metaphone'"
     ]
    }
   ],
   "source": [
    "from metaphone import doublemetaphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Алгоритм возвращает кортеж из двух возможных фонетических кодов слова. Правило такое:\n",
    "\n",
    "- (Primary Key = Primary Key) = Идеальное совпадение\n",
    "- (Secondary Key = Primary Key) = Совпадение\n",
    "- (Primary Key = Secondary Key) = Совпадение\n",
    "- (Alternate Key = Alternate Key) = Совпадение +-\n",
    "\n",
    "Идельное совпадение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doublemetaphone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-dcd4f5d3a057>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoublemetaphone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Günther Graß\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoublemetaphone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Günther Grass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doublemetaphone' is not defined"
     ]
    }
   ],
   "source": [
    "print(doublemetaphone(\"Günther Graß\"))\n",
    "print(doublemetaphone(\"Günther Grass\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совпадение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doublemetaphone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-0aa8bdf28f9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoublemetaphone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"schwartzenegger\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoublemetaphone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shwortsineger\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doublemetaphone' is not defined"
     ]
    }
   ],
   "source": [
    "print(doublemetaphone(\"schwartzenegger\"))\n",
    "print(doublemetaphone(\"shwortsineger\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doublemetaphone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-eb54e1458ef6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoublemetaphone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xerox\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoublemetaphone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"zeeerux\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doublemetaphone' is not defined"
     ]
    }
   ],
   "source": [
    "print(doublemetaphone(\"xerox\"))\n",
    "print(doublemetaphone(\"zeeerux\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Немного о динамическом программировании. Насколько дорого превращать одно слово в другое?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Динамическое программирование позволяет разбить задачу на подзадачи, решив которые можно скомпоновать финальное решение. Мы будем пытаться превратить строку source[0..i] в строку target[0..j], мы сосчитаем все возможные комбинации подстрок substrings[i, j] и рассчитаем их edit_distance до нашей исходной. Мы будем сохранять результаты в таблицу и переиспользовать их для расчета дальнейших изменений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
    "    '''\n",
    "    Input: \n",
    "        source: строка-исходник\n",
    "        target: строка, в которую мы должны исходник превратить\n",
    "        ins_cost: цена вставки\n",
    "        del_cost: цена удаления\n",
    "        rep_cost: цена замены буквы\n",
    "    Output:\n",
    "        D: матрица размера len(source)+1 на len(target)+1 содержащая минимальные расстояния edit_distance\n",
    "        med: минимальное расстояние edit_distance (med), необходимое, \n",
    "        чтобы превратить строку source в строку target\n",
    "    '''\n",
    "    # стоимость удаления и вставки = 1\n",
    "    m = len(source)\n",
    "    n = len(target)\n",
    "\n",
    "    # Заткнем нашу матрицу нулями\n",
    "    D = np.zeros((m+1, n+1), dtype=int) \n",
    "    \n",
    "    # Заполним первую колонку\n",
    "    for row in range(1,m+1): \n",
    "        D[row,0] = D[row-1,0] + del_cost\n",
    "        \n",
    "    # Заполним первую строку\n",
    "    for col in range(1,n+1): \n",
    "        D[0,col] = D[0,col-1] + ins_cost\n",
    "        \n",
    "    # Теперь пойдем от 1 к m-той строке\n",
    "    for row in range(1,m+1): \n",
    "        \n",
    "        # итерируемся по колонкам от 1 до n\n",
    "        for col in range(1,n+1):\n",
    "            \n",
    "            # r_cost - стоимость замены\n",
    "            r_cost = rep_cost\n",
    "            \n",
    "            # Совпадает ли буква исходного слова из предыдущей строки\n",
    "            # с буквой целевого слова из предыдущей колонки, \n",
    "            if source[row-1] == target[col-1]:\n",
    "                # Если они не нужны, то замена не нужна -> стоимость = 0\n",
    "                r_cost = 0\n",
    "                \n",
    "            # Обновляем значение ячейки на базе предыдущих значений \n",
    "            # Считаем D[i,j] как минимум из трех возможных стоимостей (как в формуле выше)\n",
    "            D[row,col] = min([D[row-1,col]+del_cost, D[row,col-1]+ins_cost, D[row-1,col-1]+r_cost])\n",
    "          \n",
    "    # установить edit_distance в значение из правого нижнего угла\n",
    "    med = D[m,n]\n",
    "    \n",
    "\n",
    "    return D, med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расстояние:  4 \n",
      "\n",
      "   #  s  t  a  y\n",
      "#  0  1  2  3  4\n",
      "p  1  2  3  4  5\n",
      "l  2  3  4  5  6\n",
      "a  3  4  5  4  5\n",
      "y  4  5  6  5  4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "source =  'play'\n",
    "target = 'stay'\n",
    "matrix, min_edits = min_edit_distance(source, target)\n",
    "\n",
    "print(\"Расстояние: \",min_edits, \"\\n\")\n",
    "\n",
    "idx = list('#' + source)\n",
    "cols = list('#' + target)\n",
    "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
